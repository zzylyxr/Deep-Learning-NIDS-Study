{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":394223,"sourceType":"datasetVersion","datasetId":174616},{"sourceId":10450388,"sourceType":"datasetVersion","datasetId":6452957}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\nprint(\"当前 Input 目录下的所有文件：\")\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T08:50:20.538825Z","iopub.execute_input":"2025-12-16T08:50:20.539149Z","iopub.status.idle":"2025-12-16T08:50:20.578346Z","shell.execute_reply.started":"2025-12-16T08:50:20.539124Z","shell.execute_reply":"2025-12-16T08:50:20.577138Z"}},"outputs":[{"name":"stdout","text":"当前 Input 目录下的所有文件：\n/kaggle/input/cicids2017-cleaned-and-preprocessed/cicids2017_cleaned.csv\n/kaggle/input/nslkdd/KDDTest+.arff\n/kaggle/input/nslkdd/KDDTest-21.arff\n/kaggle/input/nslkdd/KDDTest1.jpg\n/kaggle/input/nslkdd/KDDTrain+.txt\n/kaggle/input/nslkdd/KDDTrain+_20Percent.txt\n/kaggle/input/nslkdd/KDDTest-21.txt\n/kaggle/input/nslkdd/KDDTest+.txt\n/kaggle/input/nslkdd/KDDTrain+.arff\n/kaggle/input/nslkdd/index.html\n/kaggle/input/nslkdd/KDDTrain+_20Percent.arff\n/kaggle/input/nslkdd/KDDTrain1.jpg\n/kaggle/input/nslkdd/nsl-kdd/KDDTest+.arff\n/kaggle/input/nslkdd/nsl-kdd/KDDTest-21.arff\n/kaggle/input/nslkdd/nsl-kdd/KDDTest1.jpg\n/kaggle/input/nslkdd/nsl-kdd/KDDTrain+.txt\n/kaggle/input/nslkdd/nsl-kdd/KDDTrain+_20Percent.txt\n/kaggle/input/nslkdd/nsl-kdd/KDDTest-21.txt\n/kaggle/input/nslkdd/nsl-kdd/KDDTest+.txt\n/kaggle/input/nslkdd/nsl-kdd/KDDTrain+.arff\n/kaggle/input/nslkdd/nsl-kdd/index.html\n/kaggle/input/nslkdd/nsl-kdd/KDDTrain+_20Percent.arff\n/kaggle/input/nslkdd/nsl-kdd/KDDTrain1.jpg\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# --- 1. 定义 NSL-KDD 的列名 ---\n# NSL-KDD 的 txt 文件没有表头，我们需要手动加上，否则第一行数据会变成列名\nkdd_cols = [\n    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', \n    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', \n    'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', \n    'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', \n    'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', \n    'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', \n    'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', \n    'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', \n    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', \n    'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', \n    'target', 'difficulty' # 最后一列通常是难度分数，训练时不需要，但读入时得占位\n]\n\n# --- 2. 加载数据 ---\nprint(\"正在加载 NSL-KDD...\")\n# 加载训练集\ndf_nsl_train = pd.read_csv('/kaggle/input/nslkdd/KDDTrain+.txt', names=kdd_cols)\n# 加载测试集 (Day 5 验证基线时要用)\ndf_nsl_test = pd.read_csv('/kaggle/input/nslkdd/KDDTest+.txt', names=kdd_cols)\n\nprint(f\"NSL-KDD Train: {df_nsl_train.shape}\")\nprint(f\"NSL-KDD Test:  {df_nsl_test.shape}\")\n\nprint(\"\\n正在加载 CIC-IDS-2017 (Cleaned)...\")\n# 读取你找到的 cleaned 版本\ndf_cic = pd.read_csv('/kaggle/input/cicids2017-cleaned-and-preprocessed/cicids2017_cleaned.csv')\n\n# 去除 CIC-IDS 列名的空格 (这是一个常见坑)\ndf_cic.columns = df_cic.columns.str.strip()\n\nprint(f\"CIC-IDS Shape: {df_cic.shape}\")\n\n# --- 3. 标签统一与列处理 ---\nprint(\"\\n正在统一标签列名...\")\n\n# 3.1 处理 NSL-KDD\n# 删除 'difficulty' 列（这对分类任务没用）\nif 'difficulty' in df_nsl_train.columns:\n    df_nsl_train.drop('difficulty', axis=1, inplace=True)\nif 'difficulty' in df_nsl_test.columns:\n    df_nsl_test.drop('difficulty', axis=1, inplace=True)\n\n# 确保标签叫 'target' (刚才 names 里已经指定了 target，这里确认一下)\nprint(f\"NSL-KDD 标签列: {df_nsl_train.columns[-1]}\")\n\n# 3.2 处理 CIC-IDS\n# CIC-IDS 清洗版的标签列通常叫 'Label'，我们把它改成 'target' 以便代码复用\nif 'Label' in df_cic.columns:\n    df_cic.rename(columns={'Label': 'target'}, inplace=True)\n\nprint(f\"CIC-IDS 标签列: {df_cic.columns[-1]}\")\n\n# --- 4. CIC-IDS 最终清洗 (保险起见) ---\nprint(\"\\n执行 CIC-IDS 脏数据检查...\")\n\n# 即使是 cleaned 版本，也可能在转换过程中产生 NaN\n# 替换 Infinity\ndf_cic.replace([np.inf, -np.inf], np.nan, inplace=True)\n\n# 检查空值数量\nnull_count = df_cic.isna().sum().sum()\nif null_count > 0:\n    print(f\"警告：发现 {null_count} 个空值，正在删除...\")\n    df_cic.dropna(inplace=True)\nelse:\n    print(\"完美！CIC-IDS 数据中没有 NaN 或 Infinity。\")\n\nprint(\"-\" * 30)\nprint(\"P1 任务完成。当前内存中包含：\")\nprint(\"1. df_nsl_train (NSL-KDD 训练数据)\")\nprint(\"2. df_nsl_test  (NSL-KDD 测试数据)\")\nprint(\"3. df_cic       (CIC-IDS 全量数据)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T08:50:20.579893Z","iopub.execute_input":"2025-12-16T08:50:20.580179Z","iopub.status.idle":"2025-12-16T08:50:39.337053Z","shell.execute_reply.started":"2025-12-16T08:50:20.580157Z","shell.execute_reply":"2025-12-16T08:50:39.336058Z"}},"outputs":[{"name":"stdout","text":"正在加载 NSL-KDD...\nNSL-KDD Train: (125973, 43)\nNSL-KDD Test:  (22544, 43)\n\n正在加载 CIC-IDS-2017 (Cleaned)...\nCIC-IDS Shape: (2520751, 53)\n\n正在统一标签列名...\nNSL-KDD 标签列: target\nCIC-IDS 标签列: Attack Type\n\n执行 CIC-IDS 脏数据检查...\n完美！CIC-IDS 数据中没有 NaN 或 Infinity。\n------------------------------\nP1 任务完成。当前内存中包含：\n1. df_nsl_train (NSL-KDD 训练数据)\n2. df_nsl_test  (NSL-KDD 测试数据)\n3. df_cic       (CIC-IDS 全量数据)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# 1. 查看 CIC-IDS 里的所有非数字列（确认除了标签外，还有没有其他列需要 One-Hot）\nprint(\"--- CIC-IDS 非数值列 ---\")\nprint(df_cic.select_dtypes(include=['object']).columns.tolist())\n\n# 2. 查看 CIC-IDS 标签列里到底有哪些值（确认正常流量是叫 'BENIGN' 还是 'Normal'）\n# 注意：根据你刚才 P1 的反馈，列名可能还是 'Attack Type'，或者被改为 'target'\n# 我们先试着找一下存在的那个\ncic_label_col = 'target' if 'target' in df_cic.columns else 'Attack Type'\nprint(f\"\\n--- CIC-IDS 标签值分布 (前10个) ---\")\nprint(df_cic[cic_label_col].value_counts().head(10))\n\n# 3. 查看 NSL-KDD 标签列里到底有哪些值（确认正常流量是叫 'normal'）\nprint(\"\\n--- NSL-KDD 标签值分布 (前10个) ---\")\nprint(df_nsl_train['target'].value_counts().head(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T08:50:39.338081Z","iopub.execute_input":"2025-12-16T08:50:39.338379Z","iopub.status.idle":"2025-12-16T08:50:39.581254Z","shell.execute_reply.started":"2025-12-16T08:50:39.338355Z","shell.execute_reply":"2025-12-16T08:50:39.579922Z"}},"outputs":[{"name":"stdout","text":"--- CIC-IDS 非数值列 ---\n['Attack Type']\n\n--- CIC-IDS 标签值分布 (前10个) ---\nAttack Type\nNormal Traffic    2095057\nDoS                193745\nDDoS               128014\nPort Scanning       90694\nBrute Force          9150\nWeb Attacks          2143\nBots                 1948\nName: count, dtype: int64\n\n--- NSL-KDD 标签值分布 (前10个) ---\ntarget\nnormal         67343\nneptune        41214\nsatan           3633\nipsweep         3599\nportsweep       2931\nsmurf           2646\nnmap            1493\nback             956\nteardrop         892\nwarezclient      890\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport gc # 内存回收工具\n\n# --- 1. 处理 CIC-IDS (最简单，先搞定) ---\nprint(\"正在处理 CIC-IDS...\")\n\n# 1.1 强制重命名标签 (根据你的侦察结果，列名是 'Attack Type')\nif 'Attack Type' in df_cic.columns:\n    df_cic.rename(columns={'Attack Type': 'target'}, inplace=True)\n\n# 1.2 标签二值化\n# 规则：'Normal Traffic' -> 0 (正常), 其他所有 -> 1 (攻击)\ndf_cic['label_encoded'] = df_cic['target'].apply(lambda x: 0 if x == 'Normal Traffic' else 1)\n\nprint(f\"CIC-IDS 处理完毕。正常样本数: {(df_cic['label_encoded']==0).sum()}\")\n\n\n# --- 2. 处理 NSL-KDD (需要 One-Hot) ---\nprint(\"\\n正在处理 NSL-KDD...\")\n\n# 2.1 拼接 Train 和 Test\n# 为了保证训练集和测试集的 One-Hot 列完全对齐（比如训练集有 http, 测试集也有 http）\ndf_nsl_train['source'] = 'train'\ndf_nsl_test['source'] = 'test'\ndf_combined = pd.concat([df_nsl_train, df_nsl_test], axis=0)\n\n# 2.2 执行 One-Hot Encoding\n# 针对三个已知的分类特征\ncat_cols = ['protocol_type', 'service', 'flag']\nprint(f\"正在对 {cat_cols} 进行 One-Hot 编码...\")\n\ndf_combined_encoded = pd.get_dummies(df_combined, columns=cat_cols)\n\n# 2.3 拆回 Train 和 Test\ndf_nsl_train_enc = df_combined_encoded[df_combined_encoded['source'] == 'train'].drop('source', axis=1)\ndf_nsl_test_enc = df_combined_encoded[df_combined_encoded['source'] == 'test'].drop('source', axis=1)\n\n# 2.4 标签二值化\n# 规则：'normal' -> 0 (正常), 其他所有 -> 1 (攻击)\ndf_nsl_train_enc['label_encoded'] = df_nsl_train_enc['target'].apply(lambda x: 0 if x == 'normal' else 1)\ndf_nsl_test_enc['label_encoded'] = df_nsl_test_enc['target'].apply(lambda x: 0 if x == 'normal' else 1)\n\nprint(f\"NSL-KDD 处理完毕。\")\nprint(f\"Train 列数变化: {df_nsl_train.shape[1]} -> {df_nsl_train_enc.shape[1]}\")\n\n\n# --- 3. 清理内存 ---\n# 删除不再需要的原始 DataFrame\ndel df_combined, df_combined_encoded\n# 注意：暂时保留 df_nsl_train 原版，万一你想对比查看\ngc.collect()\n\nprint(\"\\n\" + \"=\"*30)\nprint(\"P2 任务执行成功！\")\nprint(f\"CIC-IDS 最终形状: {df_cic.shape} (含 label_encoded)\")\nprint(f\"NSL-KDD Train 最终形状: {df_nsl_train_enc.shape} (含 label_encoded)\")\nprint(\"=\"*30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T08:50:39.583180Z","iopub.execute_input":"2025-12-16T08:50:39.583559Z","iopub.status.idle":"2025-12-16T08:50:40.822877Z","shell.execute_reply.started":"2025-12-16T08:50:39.583531Z","shell.execute_reply":"2025-12-16T08:50:40.821715Z"}},"outputs":[{"name":"stdout","text":"正在处理 CIC-IDS...\nCIC-IDS 处理完毕。正常样本数: 2095057\n\n正在处理 NSL-KDD...\n正在对 ['protocol_type', 'service', 'flag'] 进行 One-Hot 编码...\nNSL-KDD 处理完毕。\nTrain 列数变化: 43 -> 124\n\n==============================\nP2 任务执行成功！\nCIC-IDS 最终形状: (2520751, 54) (含 label_encoded)\nNSL-KDD Train 最终形状: (125973, 124) (含 label_encoded)\n==============================\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nimport numpy as np\nimport pandas as pd\nimport os\n\n# ==========================================\n# 0. 强力清洗函数 (新增)\n# ==========================================\ndef clean_dataset_safely(df, dataset_name):\n    print(f\"[{dataset_name}] 执行深度清洗...\")\n    initial_shape = df.shape\n    \n    # 1. 强制转为数字 (处理潜在的 \"Infinity\" 字符串)\n    # errors='coerce' 会把无法转数字的变成 NaN\n    # 只对数值类型的列操作，避开 'target' 等字符串列\n    num_cols = df.select_dtypes(include=[np.number]).columns\n    # 如果有 float64 的列里混进了 object，这里强制转\n    # 注意：为了效率，我们只对可能出问题的列操作，或者简单点全量检查\n    # 这里直接处理所有非 object 列，确保万无一失\n    for col in df.columns:\n        if df[col].dtype != 'object':\n            # 检查是否有无穷大\n            if np.isinf(df[col]).any():\n                print(f\"  - 发现无穷大: 列 {col}\")\n                df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n\n    # 2. 再次删除 NaN\n    df.dropna(inplace=True)\n    \n    # 3. 再次检查无穷大 (双重保险)\n    # 仅检查数值列\n    numeric_df = df.select_dtypes(include=[np.number])\n    if np.isinf(numeric_df).values.sum() > 0:\n        print(\"  - 警告：仍存在无穷大值！尝试强制替换...\")\n        df.replace([np.inf, -np.inf], np.nan, inplace=True)\n        df.dropna(inplace=True)\n        \n    final_shape = df.shape\n    print(f\"[{dataset_name}] 清洗完成。删除行数: {initial_shape[0] - final_shape[0]}\")\n    return df\n\n# ==========================================\n# 1. 准备数据 & 应用 Log 变换\n# ==========================================\nprint(\"正在准备数据...\")\n\n# --- 关键步骤：在切分前对 CIC-IDS 做最后一次核弹级清洗 ---\n# 必须在分离 features 和 label 之前做，保证行对应关系\ndf_cic = clean_dataset_safely(df_cic, \"CIC-IDS Full\")\n\n\n# --- 定义 Log 变换函数 ---\ndef apply_log_transform(df, dataset_name):\n    cols_to_log = [c for c in df.columns if any(x in c.lower() for x in ['bytes', 'duration', 'count', 'packet'])]\n    print(f\"[{dataset_name}] 对 {len(cols_to_log)} 个特征应用 log1p...\")\n    df_log = df.copy()\n    # 再次确保没有负数 (虽然很少见)\n    # log1p 对负数会产生 NaN，这里做一个 clip 保护\n    for col in cols_to_log:\n        df_log[col] = df_log[col].clip(lower=0)\n        \n    df_log[cols_to_log] = df_log[cols_to_log].apply(np.log1p)\n    return df_log\n\n# --- 提取特征与标签 ---\n\n# 1. NSL-KDD\nnsl_drop = ['target', 'label_encoded']\ndf_nsl_features = df_nsl_train_enc.drop(nsl_drop, axis=1)\ndf_nsl_features = apply_log_transform(df_nsl_features, \"NSL-KDD Train\")\ny_nsl_train_full = df_nsl_train_enc['label_encoded']\n\ndf_nsl_test_features = df_nsl_test_enc.drop(nsl_drop, axis=1)\ndf_nsl_test_features = apply_log_transform(df_nsl_test_features, \"NSL-KDD Test\")\ny_nsl_test = df_nsl_test_enc['label_encoded']\n\n# 2. CIC-IDS (已经清洗过)\ncic_drop = ['target', 'label_encoded']\ndf_cic_features = df_cic.drop(cic_drop, axis=1)\ndf_cic_features = apply_log_transform(df_cic_features, \"CIC-IDS\")\ny_cic_full = df_cic['label_encoded']\n\n\n# ==========================================\n# 2. P4: 数据集切分 (Split)\n# ==========================================\nprint(\"\\n正在执行数据集切分...\")\n\n# NSL-KDD\nX_nsl_train, X_nsl_val, y_nsl_train, y_nsl_val = train_test_split(\n    df_nsl_features, y_nsl_train_full, \n    test_size=0.1, random_state=42, stratify=y_nsl_train_full\n)\nX_nsl_test = df_nsl_test_features\n\n# CIC-IDS\nX_cic_temp, X_cic_test, y_cic_temp, y_cic_test = train_test_split(\n    df_cic_features, y_cic_full, \n    test_size=0.2, random_state=42, stratify=y_cic_full\n)\nX_cic_train, X_cic_val, y_cic_train, y_cic_val = train_test_split(\n    X_cic_temp, y_cic_temp, \n    test_size=0.125, random_state=42, stratify=y_cic_temp\n)\n\nprint(f\"切分完成。CIC-IDS Train: {X_cic_train.shape}\")\n\n\n# ==========================================\n# 3. P3: 数值标准化 (MinMax Scaling)\n# ==========================================\nprint(\"\\n正在进行归一化 (MinMax Scaling)...\")\n\nscaler_nsl = MinMaxScaler()\nX_nsl_train = scaler_nsl.fit_transform(X_nsl_train)\nX_nsl_val   = scaler_nsl.transform(X_nsl_val)\nX_nsl_test  = scaler_nsl.transform(X_nsl_test)\n\nscaler_cic = MinMaxScaler()\n# 这里如果再报错，那就是玄学了，因为我们在第一步已经清洗得非常彻底\nX_cic_train = scaler_cic.fit_transform(X_cic_train)\nX_cic_val   = scaler_cic.transform(X_cic_val)\nX_cic_test  = scaler_cic.transform(X_cic_test)\n\nprint(\"归一化完成。\")\n\n\n# ==========================================\n# 4. P5: 数据持久化 (Saving)\n# ==========================================\nprint(\"\\n正在保存最终数据...\")\nsave_dir = '/kaggle/working/'\n\nnp.savez_compressed(\n    os.path.join(save_dir, 'nsl_kdd_processed.npz'),\n    X_train=X_nsl_train, y_train=y_nsl_train,\n    X_val=X_nsl_val,     y_val=y_nsl_val,\n    X_test=X_nsl_test,   y_test=y_nsl_test\n)\n\nnp.savez_compressed(\n    os.path.join(save_dir, 'cic_ids_processed.npz'),\n    X_train=X_cic_train, y_train=y_cic_train,\n    X_val=X_cic_val,     y_val=y_cic_val,\n    X_test=X_cic_test,   y_test=y_cic_test\n)\n\nprint(\"Day 4 任务（终极版）圆满结束！\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T08:50:40.823874Z","iopub.execute_input":"2025-12-16T08:50:40.824133Z","iopub.status.idle":"2025-12-16T08:51:43.836573Z","shell.execute_reply.started":"2025-12-16T08:50:40.824114Z","shell.execute_reply":"2025-12-16T08:51:43.835398Z"}},"outputs":[{"name":"stdout","text":"正在准备数据...\n[CIC-IDS Full] 执行深度清洗...\n[CIC-IDS Full] 清洗完成。删除行数: 0\n[NSL-KDD Train] 对 7 个特征应用 log1p...\n[NSL-KDD Test] 对 7 个特征应用 log1p...\n[CIC-IDS] 对 27 个特征应用 log1p...\n\n正在执行数据集切分...\n切分完成。CIC-IDS Train: (1764525, 52)\n\n正在进行归一化 (MinMax Scaling)...\n归一化完成。\n\n正在保存最终数据...\nDay 4 任务（终极版）圆满结束！\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import joblib\nimport os\n\nsave_dir = '/kaggle/working/'\n\nprint(\"正在补存 Scaler 对象...\")\n\n# 保存 NSL-KDD 的 scaler (包含 log 后的 min/max 信息)\njoblib.dump(scaler_nsl, os.path.join(save_dir, 'scaler_nsl.pkl'))\n\n# 保存 CIC-IDS 的 scaler\njoblib.dump(scaler_cic, os.path.join(save_dir, 'scaler_cic.pkl'))\n\nprint(f\"Scaler 对象已保存至: {save_dir}\")\nprint(\"包含文件: scaler_nsl.pkl, scaler_cic.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T08:51:43.837924Z","iopub.execute_input":"2025-12-16T08:51:43.838476Z","iopub.status.idle":"2025-12-16T08:51:43.850027Z","shell.execute_reply.started":"2025-12-16T08:51:43.838443Z","shell.execute_reply":"2025-12-16T08:51:43.848783Z"}},"outputs":[{"name":"stdout","text":"正在补存 Scaler 对象...\nScaler 对象已保存至: /kaggle/working/\n包含文件: scaler_nsl.pkl, scaler_cic.pkl\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\n\n# 设置显示选项，确保所有列都能印出来，不被折叠\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 100)\n\ndef audit_columns(df, name):\n    print(f\"\\n======== {name} 数据列审计 ========\")\n    print(f\"总行数: {df.shape[0]}, 总列数: {df.shape[1]}\")\n    print(\"-\" * 80)\n    print(f\"{'列名':<30} | {'类型':<10} | {'唯一值数量':<10} | {'前5个样例值'}\")\n    print(\"-\" * 80)\n    \n    for col in df.columns:\n        # 获取该列的前5个非空值\n        sample_vals = df[col].dropna().unique()[:5]\n        # 获取类型\n        dtype = str(df[col].dtype)\n        # 获取唯一值数量\n        n_unique = df[col].nunique()\n        \n        print(f\"{col:<30} | {dtype:<10} | {n_unique:<10} | {sample_vals}\")\n\n# 检查内存中是否存在原始数据\n# 如果你之前运行了 del df_cic, 这里可能需要你重新运行一下 P1 的加载代码\nif 'df_cic' in locals():\n    # 只需要看 CIC-IDS，因为 NSL-KDD 我们已经很清楚了 (protocol/service/flag)\n    # 但为了保险，两个都看一眼\n    audit_columns(df_cic, \"CIC-IDS (Cleaned)\")\nelse:\n    print(\"错误：内存中找不到 df_cic。请重新运行 P1 (加载数据) 步骤后再运行此代码。\")\n\nif 'df_nsl_train' in locals():\n    audit_columns(df_nsl_train, \"NSL-KDD Train\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T08:56:23.345710Z","iopub.execute_input":"2025-12-16T08:56:23.346740Z","iopub.status.idle":"2025-12-16T08:56:29.280197Z","shell.execute_reply.started":"2025-12-16T08:56:23.346607Z","shell.execute_reply":"2025-12-16T08:56:29.279195Z"}},"outputs":[{"name":"stdout","text":"\n======== CIC-IDS (Cleaned) 数据列审计 ========\n总行数: 2520751, 总列数: 54\n--------------------------------------------------------------------------------\n列名                             | 类型         | 唯一值数量      | 前5个样例值\n--------------------------------------------------------------------------------\nDestination Port               | int64      | 53791      | [   22 35396 60058 60060 35398]\nFlow Duration                  | int64      | 1050854    | [1266342 1319353     160 1303488      77]\nTotal Fwd Packets              | int64      | 1413       | [41  1  2 15 19]\nTotal Length of Fwd Packets    | int64      | 17913      | [ 2664     0  2728  2071 18467]\nFwd Packet Length Max          | int64      | 5279       | [ 456    0 2065 2920   43]\nFwd Packet Length Min          | int64      | 384        | [ 0  6 48 45 34]\nFwd Packet Length Mean         | float64    | 99681      | [  64.97560976    0.           66.53658537 1035.5        1231.133333  ]\nFwd Packet Length Std          | float64    | 253866     | [ 109.864573     0.         110.1299454 1455.932862  1054.492489 ]\nBwd Packet Length Max          | int64      | 4836       | [976   0   6  51  48]\nBwd Packet Length Min          | int64      | 583        | [ 0  6 48 61 50]\nBwd Packet Length Mean         | float64    | 147599     | [158.0454545   0.        157.952381  165.85        4.       ]\nBwd Packet Length Std          | float64    | 248853     | [312.6752498    0.         319.1214275  325.1423791    3.09838668]\nFlow Bytes/s                   | float64    | 1593862    | [7595.10464  7289.93681     0.       7182.267884 7161.659039]\nFlow Packets/s                 | float64    | 1240118    | [   67.12246771    64.42551766 12500.            63.6753081\n 38961.03896   ]\nFlow IAT Mean                  | float64    | 1166266    | [15075.5     15706.58333   160.      15896.19512    38.5    ]\nFlow IAT Std                   | float64    | 1056605    | [1.04051400e+05 1.04861870e+05 0.00000000e+00 1.06554899e+05\n 1.48492424e+01]\nFlow IAT Max                   | int64      | 580272     | [948537 955790    160 956551     49]\nFlow IAT Min                   | int64      | 136315     | [  0   1 160  28 244]\nFwd IAT Total                  | int64      | 493094     | [1266342 1319353       0 1303488 1307239]\nFwd IAT Mean                   | float64    | 737693     | [31658.55  32983.825     0.    32587.2   32680.975]\nFwd IAT Std                    | float64    | 700282     | [159355.2595 159247.9008      0.     160397.0499 159066.9939]\nFwd IAT Max                    | int64      | 437304     | [996324 996423      0 997357 997887]\nFwd IAT Min                    | int64      | 110629     | [  2   1   0   3 153]\nBwd IAT Total                  | int64      | 414927     | [317671 363429      0 346851     49]\nBwd IAT Mean                   | float64    | 670782     | [7387.697674 8451.837209    0.       8459.780488   49.      ]\nBwd IAT Std                    | float64    | 709014     | [19636.44809 21337.26261     0.      23962.23892 20369.77643]\nBwd IAT Max                    | int64      | 368273     | [104616 104815      0 138295     49]\nBwd IAT Min                    | int64      | 66074      | [ 1  0 49 48  2]\nFwd Header Length              | int64      | 3750       | [1328   32   40  324  404]\nBwd Header Length              | int64      | 3925       | [1424   32 1360   64 1296]\nFwd Packets/s                  | float64    | 1220378    | [   32.37671972    31.07583793  6250.            31.45406785\n 12987.01299   ]\nBwd Packets/s                  | float64    | 1107842    | [   34.74574799    33.34967973  6250.            32.22124024\n 25974.02597   ]\nMin Packet Length              | int64      | 215        | [ 0  6 48 45 34]\nMax Packet Length              | int64      | 5707       | [ 976    0 2065 2920   51]\nPacket Length Mean             | float64    | 215787     | [ 111.8372093    0.         111.452381   114.1707317 1378.666667 ]\nPacket Length Std              | float64    | 412201     | [ 239.6868477    0.         241.6427915  243.964772  1188.764204 ]\nPacket Length Variance         | float64    | 405520     | [  57449.78495       0.        58391.23867   59518.81    1413160.333  ]\nFIN Flag Count                 | int64      | 2          | [0 1]\nPSH Flag Count                 | int64      | 2          | [1 0]\nACK Flag Count                 | int64      | 2          | [0 1]\nAverage Packet Size            | float64    | 212179     | [ 113.1529412    0.         112.7951807  115.5802469 2068.       ]\nSubflow Fwd Bytes              | int64      | 17913      | [ 2664     0  2728  2071 18467]\nInit_Win_bytes_forward         | int64      | 12142      | [29200   290   243   256  8192]\nInit_Win_bytes_backward        | int64      | 13109      | [243 290  -1 357 229]\nact_data_pkt_fwd               | int64      | 1083       | [24  0  1 13 17]\nmin_seg_size_forward           | int64      | 28         | [32 20  0 28 40]\nActive Mean                    | float64    | 326301     | [0.00000000e+00 3.29185757e+06 2.02220000e+04 2.44560000e+04\n 3.57142857e+02]\nActive Max                     | int64      | 299547     | [      0 9795862   20222   24456     370]\nActive Min                     | int64      | 175648     | [    0    66 20222 24456   338]\nIdle Mean                      | float64    | 222012     | [       0.   9420803.7 55000000.  55100000.  16100000. ]\nIdle Max                       | int64      | 149733     | [       0 20000000 55000000 55100000 16400000]\nIdle Min                       | int64      | 223878     | [       0  5046092 55000000 55100000 15400000]\ntarget                         | object     | 7          | ['Normal Traffic' 'Port Scanning' 'Web Attacks' 'Brute Force' 'DDoS']\nlabel_encoded                  | int64      | 2          | [0 1]\n\n======== NSL-KDD Train 数据列审计 ========\n总行数: 125973, 总列数: 43\n--------------------------------------------------------------------------------\n列名                             | 类型         | 唯一值数量      | 前5个样例值\n--------------------------------------------------------------------------------\nduration                       | int64      | 2981       | [   0 5607  507    1    2]\nprotocol_type                  | object     | 3          | ['tcp' 'udp' 'icmp']\nservice                        | object     | 70         | ['ftp_data' 'other' 'private' 'http' 'remote_job']\nflag                           | object     | 11         | ['SF' 'S0' 'REJ' 'RSTR' 'SH']\nsrc_bytes                      | int64      | 3341       | [491 146   0 232 199]\ndst_bytes                      | int64      | 9326       | [    0  8153   420  2251 13788]\nland                           | int64      | 2          | [0 1]\nwrong_fragment                 | int64      | 3          | [0 3 1]\nurgent                         | int64      | 4          | [0 1 3 2]\nhot                            | int64      | 28         | [0 5 6 4 2]\nnum_failed_logins              | int64      | 6          | [0 2 1 3 4]\nlogged_in                      | int64      | 2          | [0 1]\nnum_compromised                | int64      | 88         | [ 0  3  2  1 19]\nroot_shell                     | int64      | 2          | [0 1]\nsu_attempted                   | int64      | 3          | [0 1 2]\nnum_root                       | int64      | 82         | [ 0  9 10  1  5]\nnum_file_creations             | int64      | 35         | [0 1 8 4 2]\nnum_shells                     | int64      | 3          | [0 1 2]\nnum_access_files               | int64      | 10         | [0 1 2 3 5]\nnum_outbound_cmds              | int64      | 1          | [0]\nis_host_login                  | int64      | 2          | [0 1]\nis_guest_login                 | int64      | 2          | [0 1]\ncount                          | int64      | 512        | [  2  13 123   5  30]\nsrv_count                      | int64      | 509        | [ 2  1  6  5 32]\nserror_rate                    | float64    | 89         | [0.   1.   0.2  0.02 0.1 ]\nsrv_serror_rate                | float64    | 86         | [0.   1.   0.2  0.11 0.02]\nrerror_rate                    | float64    | 82         | [0.   1.   0.03 0.89 0.94]\nsrv_rerror_rate                | float64    | 62         | [0.   1.   0.03 0.1  0.2 ]\nsame_srv_rate                  | float64    | 101        | [1.   0.08 0.05 0.16 0.14]\ndiff_srv_rate                  | float64    | 95         | [0.   0.15 0.07 0.06 0.05]\nsrv_diff_host_rate             | float64    | 60         | [0.   0.09 0.43 0.22 0.2 ]\ndst_host_count                 | int64      | 256        | [150 255  30   8   2]\ndst_host_srv_count             | int64      | 256        | [ 25   1  26 255  19]\ndst_host_same_srv_rate         | float64    | 101        | [0.17 0.   0.1  1.   0.07]\ndst_host_diff_srv_rate         | float64    | 101        | [0.03 0.6  0.05 0.   0.07]\ndst_host_same_src_port_rate    | float64    | 101        | [0.17 0.88 0.   0.03 0.12]\ndst_host_srv_diff_host_rate    | float64    | 75         | [0.   0.04 0.03 0.2  0.02]\ndst_host_serror_rate           | float64    | 101        | [0.   1.   0.03 0.99 0.53]\ndst_host_srv_serror_rate       | float64    | 100        | [0.   1.   0.01 0.02 0.88]\ndst_host_rerror_rate           | float64    | 101        | [0.05 0.   1.   0.02 0.56]\ndst_host_srv_rerror_rate       | float64    | 101        | [0.   0.01 1.   0.16 0.57]\ntarget                         | object     | 23         | ['normal' 'neptune' 'warezclient' 'ipsweep' 'portsweep']\nsource                         | object     | 1          | ['train']\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"------------------------------------------------------------------------------------------\n# 以下是重新进行的Day4的代码运行","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\n\n# ==========================================\n# 1. 定义清洗函数 (集成之前的修复经验)\n# ==========================================\ndef clean_dataset_safely(df, dataset_name):\n    print(f\"[{dataset_name}] 正在执行深度清洗...\")\n    initial_shape = df.shape\n    \n    # 策略：\n    # 1. 显式查找无穷大 (np.inf, -np.inf) 并替换为 NaN\n    # 2. 针对 object 列之外的所有列，检查数值合法性\n    \n    # 仅选择数值类型的列进行检查\n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    \n    # 检查并替换 Inf\n    if np.isinf(df[numeric_cols]).values.sum() > 0:\n        print(f\"  - 警告：发现数值列包含无穷大，正在替换...\")\n        df.replace([np.inf, -np.inf], np.nan, inplace=True)\n        \n    # 再次检查 NaN (包含原本的 NaN 和由 Inf 变来的 NaN)\n    if df.isna().sum().sum() > 0:\n        print(f\"  - 发现空值 (NaN)，准备删除...\")\n        df.dropna(inplace=True)\n        \n    final_shape = df.shape\n    print(f\"[{dataset_name}] 清洗完成。删除行数: {initial_shape[0] - final_shape[0]}\")\n    return df\n\n# ==========================================\n# 2. 加载 NSL-KDD\n# ==========================================\nprint(\"正在加载 NSL-KDD...\")\nkdd_cols = [\n    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', \n    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', \n    'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', \n    'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', \n    'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', \n    'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', \n    'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', \n    'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', \n    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', \n    'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', \n    'target', 'difficulty'\n]\n\n# 路径根据你之前的运行记录\ndf_nsl_train = pd.read_csv('/kaggle/input/nslkdd/KDDTrain+.txt', names=kdd_cols)\ndf_nsl_test = pd.read_csv('/kaggle/input/nslkdd/KDDTest+.txt', names=kdd_cols)\n\n# 删除 difficulty 列\nif 'difficulty' in df_nsl_train.columns: df_nsl_train.drop('difficulty', axis=1, inplace=True)\nif 'difficulty' in df_nsl_test.columns: df_nsl_test.drop('difficulty', axis=1, inplace=True)\n\nprint(f\"NSL-KDD Train: {df_nsl_train.shape}\")\n\n# ==========================================\n# 3. 加载 CIC-IDS & 深度清洗\n# ==========================================\nprint(\"\\n正在加载 CIC-IDS (Cleaned)...\")\ndf_cic = pd.read_csv('/kaggle/input/cicids2017-cleaned-and-preprocessed/cicids2017_cleaned.csv')\n\n# 去除列名空格\ndf_cic.columns = df_cic.columns.str.strip()\n\n# 统一标签名：CIC-IDS 可能是 'Label' 或 'Attack Type'\nif 'Label' in df_cic.columns:\n    df_cic.rename(columns={'Label': 'target'}, inplace=True)\nelif 'Attack Type' in df_cic.columns:\n    df_cic.rename(columns={'Attack Type': 'target'}, inplace=True)\n\n# 执行深度清洗\ndf_cic = clean_dataset_safely(df_cic, \"CIC-IDS Full\")\n\nprint(\"-\" * 30)\nprint(\"P1 完成。所有数据集已加载并去除了脏数据。\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T09:13:49.722394Z","iopub.execute_input":"2025-12-16T09:13:49.723138Z","iopub.status.idle":"2025-12-16T09:14:06.168583Z","shell.execute_reply.started":"2025-12-16T09:13:49.723101Z","shell.execute_reply":"2025-12-16T09:14:06.167455Z"}},"outputs":[{"name":"stdout","text":"正在加载 NSL-KDD...\nNSL-KDD Train: (125973, 42)\n\n正在加载 CIC-IDS (Cleaned)...\n[CIC-IDS Full] 正在执行深度清洗...\n[CIC-IDS Full] 清洗完成。删除行数: 0\n------------------------------\nP1 完成。所有数据集已加载并去除了脏数据。\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport gc\n\n# ==========================================\n# 1. CIC-IDS 处理 (基于列审计结果)\n# ==========================================\nprint(\"正在处理 CIC-IDS 特征...\")\n\n# [审计结论] 剔除 'Destination Port'，因为它有 53791 个唯一值，做数值处理无意义，做 One-Hot 会内存爆炸\nif 'Destination Port' in df_cic.columns:\n    print(\"  - 剔除 'Destination Port' 列 (避免维度爆炸)...\")\n    df_cic.drop('Destination Port', axis=1, inplace=True)\n\n# 标签二值化：'Normal Traffic' -> 0, 其他 -> 1\n# 注意：基于之前的 print 结果，正常标签是 'Normal Traffic'\ndf_cic['label_encoded'] = df_cic['target'].apply(lambda x: 0 if x == 'Normal Traffic' else 1)\n\nprint(f\"CIC-IDS 处理完毕。特征数: {df_cic.shape[1]}\")\n\n\n# ==========================================\n# 2. NSL-KDD 处理 (One-Hot)\n# ==========================================\nprint(\"\\n正在处理 NSL-KDD 特征...\")\n\n# 拼接 Train/Test 以保证 One-Hot 维度对齐\ndf_nsl_train['source'] = 'train'\ndf_nsl_test['source'] = 'test'\ndf_combined = pd.concat([df_nsl_train, df_nsl_test], axis=0)\n\n# 指定需要编码的列 (NSL-KDD 的三个典型分类特征)\ncat_cols = ['protocol_type', 'service', 'flag']\nprint(f\"  - 执行 One-Hot 编码: {cat_cols}\")\ndf_combined_encoded = pd.get_dummies(df_combined, columns=cat_cols)\n\n# 拆分回 Train/Test\ndf_nsl_train_enc = df_combined_encoded[df_combined_encoded['source'] == 'train'].drop('source', axis=1)\ndf_nsl_test_enc = df_combined_encoded[df_combined_encoded['source'] == 'test'].drop('source', axis=1)\n\n# 标签二值化：'normal' -> 0, 其他 -> 1\ndf_nsl_train_enc['label_encoded'] = df_nsl_train_enc['target'].apply(lambda x: 0 if x == 'normal' else 1)\ndf_nsl_test_enc['label_encoded'] = df_nsl_test_enc['target'].apply(lambda x: 0 if x == 'normal' else 1)\n\nprint(f\"NSL-KDD 处理完毕。Train 维度: {df_nsl_train_enc.shape}\")\n\n\n# ==========================================\n# 3. 内存清理\n# ==========================================\ndel df_combined, df_combined_encoded\ngc.collect()\n\nprint(\"\\n\" + \"=\"*30)\nprint(\"P2 完成。分类特征已编码，标签已二值化。\")\nprint(f\"当前内存中的关键变量: df_cic, df_nsl_train_enc, df_nsl_test_enc\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T09:17:27.075790Z","iopub.execute_input":"2025-12-16T09:17:27.076134Z","iopub.status.idle":"2025-12-16T09:17:28.466942Z","shell.execute_reply.started":"2025-12-16T09:17:27.076112Z","shell.execute_reply":"2025-12-16T09:17:28.465875Z"}},"outputs":[{"name":"stdout","text":"正在处理 CIC-IDS 特征...\n  - 剔除 'Destination Port' 列 (避免维度爆炸)...\nCIC-IDS 处理完毕。特征数: 53\n\n正在处理 NSL-KDD 特征...\n  - 执行 One-Hot 编码: ['protocol_type', 'service', 'flag']\nNSL-KDD 处理完毕。Train 维度: (125973, 124)\n\n==============================\nP2 完成。分类特征已编码，标签已二值化。\n当前内存中的关键变量: df_cic, df_nsl_train_enc, df_nsl_test_enc\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# ==========================================\n# 1. 定义 Log 变换函数\n# ==========================================\ndef apply_log_transform(df, dataset_name):\n    # 筛选包含 bytes, duration, count, packet 的列\n    cols_to_log = [c for c in df.columns if any(x in c.lower() for x in ['bytes', 'duration', 'count', 'packet'])]\n    print(f\"[{dataset_name}] 正在对 {len(cols_to_log)} 个长尾特征应用 log1p 变换...\")\n    \n    df_log = df.copy()\n    # 保护性 Clip，防止极少数负数导致 NaN (虽然理论上不该有)\n    for col in cols_to_log:\n        df_log[col] = df_log[col].clip(lower=0)\n    \n    # log1p = log(x+1)\n    df_log[cols_to_log] = df_log[cols_to_log].apply(np.log1p)\n    return df_log\n\n# ==========================================\n# 2. 准备 NSL-KDD 数据\n# ==========================================\nprint(\"正在提取 NSL-KDD 特征...\")\nnsl_drop = ['target', 'label_encoded']\n# 如果 'source' 列还残留，也删掉\nif 'source' in df_nsl_train_enc.columns: nsl_drop.append('source')\n\n# 提取特征并应用 Log\nX_nsl_train_raw = apply_log_transform(df_nsl_train_enc.drop(nsl_drop, axis=1), \"NSL-KDD Train\")\ny_nsl_train_full = df_nsl_train_enc['label_encoded']\n\nX_nsl_test_raw = apply_log_transform(df_nsl_test_enc.drop(nsl_drop, axis=1), \"NSL-KDD Test\")\ny_nsl_test = df_nsl_test_enc['label_encoded']\n\n# ==========================================\n# 3. 准备 CIC-IDS 数据\n# ==========================================\nprint(\"\\n正在提取 CIC-IDS 特征...\")\ncic_drop = ['target', 'label_encoded']\n\nX_cic_raw = apply_log_transform(df_cic.drop(cic_drop, axis=1), \"CIC-IDS Full\")\ny_cic_full = df_cic['label_encoded']\n\nprint(\"-\" * 30)\nprint(\"P3 (特征提取) 完成。\")\nprint(f\"NSL-KDD 特征维度: {X_nsl_train_raw.shape}\")\nprint(f\"CIC-IDS 特征维度: {X_cic_raw.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T09:18:39.840073Z","iopub.execute_input":"2025-12-16T09:18:39.840377Z","iopub.status.idle":"2025-12-16T09:18:42.076106Z","shell.execute_reply.started":"2025-12-16T09:18:39.840357Z","shell.execute_reply":"2025-12-16T09:18:42.074573Z"}},"outputs":[{"name":"stdout","text":"正在提取 NSL-KDD 特征...\n[NSL-KDD Train] 正在对 7 个长尾特征应用 log1p 变换...\n[NSL-KDD Test] 正在对 7 个长尾特征应用 log1p 变换...\n\n正在提取 CIC-IDS 特征...\n[CIC-IDS Full] 正在对 27 个长尾特征应用 log1p 变换...\n------------------------------\nP3 (特征提取) 完成。\nNSL-KDD 特征维度: (125973, 122)\nCIC-IDS 特征维度: (2520751, 51)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nprint(\"正在执行数据集切分 (Stratified Split)...\")\n\n# ==========================================\n# 1. NSL-KDD 切分\n# ==========================================\n# 原始 Train 拆分为: 真正的 Train (90%) + Validation (10%)\n# 原始 Test 保持不变\nX_nsl_train, X_nsl_val, y_nsl_train, y_nsl_val = train_test_split(\n    X_nsl_train_raw, y_nsl_train_full, \n    test_size=0.1, random_state=42, stratify=y_nsl_train_full\n)\n# Test 集直接赋值\nX_nsl_test = X_nsl_test_raw\n\n# ==========================================\n# 2. CIC-IDS 切分\n# ==========================================\n# 目标: Train(70%), Val(10%), Test(20%)\n\n# 第一刀: 切出 20% 做最终测试集 (Test)\nX_cic_temp, X_cic_test, y_cic_temp, y_cic_test = train_test_split(\n    X_cic_raw, y_cic_full, \n    test_size=0.2, random_state=42, stratify=y_cic_full\n)\n\n# 第二刀: 从剩余 80% 中切出 12.5% (即总量的 10%) 做验证集 (Val)\nX_cic_train, X_cic_val, y_cic_train, y_cic_val = train_test_split(\n    X_cic_temp, y_cic_temp, \n    test_size=0.125, random_state=42, stratify=y_cic_temp\n)\n\nprint(\"-\" * 30)\nprint(\"P4 (数据切分) 完成。\")\nprint(f\"NSL-KDD: Train={X_nsl_train.shape}, Val={X_nsl_val.shape}, Test={X_nsl_test.shape}\")\nprint(f\"CIC-IDS: Train={X_cic_train.shape}, Val={X_cic_val.shape}, Test={X_cic_test.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T09:19:13.065035Z","iopub.execute_input":"2025-12-16T09:19:13.065351Z","iopub.status.idle":"2025-12-16T09:19:19.141647Z","shell.execute_reply.started":"2025-12-16T09:19:13.065329Z","shell.execute_reply":"2025-12-16T09:19:19.140242Z"}},"outputs":[{"name":"stdout","text":"正在执行数据集切分 (Stratified Split)...\n------------------------------\nP4 (数据切分) 完成。\nNSL-KDD: Train=(113375, 122), Val=(12598, 122), Test=(22544, 122)\nCIC-IDS: Train=(1764525, 51), Val=(252075, 51), Test=(504151, 51)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nimport joblib\nimport os\n\nprint(\"正在进行归一化 (MinMax Scaling) 与 保存...\")\nsave_dir = '/kaggle/working/'\n\n# ==========================================\n# 1. NSL-KDD 标准化 & 保存\n# ==========================================\nscaler_nsl = MinMaxScaler()\n# Fit on Train\nX_nsl_train = scaler_nsl.fit_transform(X_nsl_train)\n# Transform others\nX_nsl_val   = scaler_nsl.transform(X_nsl_val)\nX_nsl_test  = scaler_nsl.transform(X_nsl_test)\n\n# 保存 Scaler\njoblib.dump(scaler_nsl, os.path.join(save_dir, 'scaler_nsl.pkl'))\n\n# 保存数据\nnp.savez_compressed(\n    os.path.join(save_dir, 'nsl_kdd_processed.npz'),\n    X_train=X_nsl_train, y_train=y_nsl_train,\n    X_val=X_nsl_val,     y_val=y_nsl_val,\n    X_test=X_nsl_test,   y_test=y_nsl_test\n)\nprint(\"  - NSL-KDD 处理完成并保存。\")\n\n# ==========================================\n# 2. CIC-IDS 标准化 & 保存\n# ==========================================\nscaler_cic = MinMaxScaler()\n# Fit on Train\nX_cic_train = scaler_cic.fit_transform(X_cic_train)\n# Transform others\nX_cic_val   = scaler_cic.transform(X_cic_val)\nX_cic_test  = scaler_cic.transform(X_cic_test)\n\n# 保存 Scaler\njoblib.dump(scaler_cic, os.path.join(save_dir, 'scaler_cic.pkl'))\n\n# 保存数据\nnp.savez_compressed(\n    os.path.join(save_dir, 'cic_ids_processed.npz'),\n    X_train=X_cic_train, y_train=y_cic_train,\n    X_val=X_cic_val,     y_val=y_cic_val,\n    X_test=X_cic_test,   y_test=y_cic_test\n)\nprint(\"  - CIC-IDS 处理完成并保存。\")\n\nprint(\"=\" * 30)\nprint(\"Day 4 任务圆满成功！\")\nprint(f\"文件输出目录: {save_dir}\")\nprint(\"包含文件: nsl_kdd_processed.npz, cic_ids_processed.npz, scaler_nsl.pkl, scaler_cic.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T09:20:25.740991Z","iopub.execute_input":"2025-12-16T09:20:25.741300Z","iopub.status.idle":"2025-12-16T09:21:16.830637Z","shell.execute_reply.started":"2025-12-16T09:20:25.741280Z","shell.execute_reply":"2025-12-16T09:21:16.829292Z"}},"outputs":[{"name":"stdout","text":"正在进行归一化 (MinMax Scaling) 与 保存...\n  - NSL-KDD 处理完成并保存。\n  - CIC-IDS 处理完成并保存。\n==============================\nDay 4 任务圆满成功！\n文件输出目录: /kaggle/working/\n包含文件: nsl_kdd_processed.npz, cic_ids_processed.npz, scaler_nsl.pkl, scaler_cic.pkl\n","output_type":"stream"}],"execution_count":13}]}